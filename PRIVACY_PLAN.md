# Privacy & Security Strategy: Synthetic Data Generation

## The Core Requirement
**"Entirely mocked up data is fine to feed into AI, but we can't send obfuscated data to AI."**

### Interpretation
This directive, derived from security best practices, distinguishes between two approaches to data privacy:

1.  **Obfuscation (Masking/Redaction)**: Taking real data and trying to hide sensitive parts (e.g., replacing names with `X`, masking SSNs).
    *   **Status**: ❌ **FORBIDDEN**
    *   **Reason**: It is mathematically impossible to *prove* that an obfuscation technique is perfect. A single missed field, a leaked pattern, or a "notes" column containing copied PII can result in a data breach. The lineage of the data is still "real customer data."

2.  **Synthetic Data (Mocking)**: Generating entirely new data from scratch based on abstract patterns.
    *   **Status**: ✅ **APPROVED**
    *   **Reason**: Synthetic data has **zero lineage** to real customer records. It is generated by random number generators and standard libraries (like `faker`). Even if a synthetic row looks like "John Doe, 555-0199", it refers to nobody. It is provably safe because it was never real.

## Implementation Plan

To comply with this requirement, we are refactoring `AgentSQL` to remove all transmission of real data samples.

### Old Flow (Unsafe)
1.  Read `input.csv`.
2.  Select first 20 rows (`LIMIT 20`).
3.  Send these 20 real rows to the LLM to explain the schema.
4.  **Risk**: Leaks PII contained in those 20 rows.

### New Flow (Safe)
1.  Read `input.csv` locally.
2.  **Analyze Metadata**: Calculate statistics and patterns (e.g., "Column `phone` is a string, 10 digits, starts with 555").
3.  **Generate Synthetic Data**: Use a random generator to create 5 *fake* rows that match those patterns.
4.  Send these 5 **fake** rows to the LLM.
5.  **Safety**: The LLM never sees a single byte of real customer data.

## Technical Components

*   **`src/agent_sql/synthetic.py`**: A new module responsible for:
    *   **Profiling**: Scanning columns to detect types (Integer, Date, Email, Phone, etc.).
    *   **Generation**: Using libraries like `faker` to produce realistic-looking but fake values.
*   **`src/agent_sql/core.py`**: Updated to call the synthetic generator instead of raw sampling.

This approach allows the AI to understand the *shape* and *nature* of the data (needed to write SQL) without ever accessing the *content* of the data.
